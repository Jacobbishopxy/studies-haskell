\documentclass[./main.tex]{subfiles}

\begin{document}

\subsection*{定义并发与并行}

一个\textit{并发}程序需要在同一时刻执行若干不相关的任务。假设一个游戏服务器：它由多个组件构成，每个组件都要与外界进行复杂的交互。某个组件可能是处理多用户聊天；若干个
则是处理用户的输入，并将更新后的状态返回给用户；另外一些则是执行物理计算。

一个并发程序的正确操作并不需要多核，不过多核可以增强性能与响应。

相反的，一个\textit{并行}程序解决单个问题。假设一个金融模型用于预测单个股票下一分钟的价格。如果我们希望将此模型应用在交易所中的每个股票上，例如预计哪只票可以进行买卖，
那么通过五百个核进行计算肯定比一个核计算更能快速的得到一个答案。这种情况下，并行程序通常不依靠多核也能正确工作。

另一个用于区分两者差别的方法在于它们如何与外界进行交互。根据定义，一个并发程序会持续不断地进行网络协议，数据库等处理。而一个典型的并行程序则更为集中：它流式的接受数据，
处理一段时间（进行少许 I/O），然后流式的输出数据。

很多传统语言会模糊这两者之间的边界，因为它们强制程序员使用相同的方式构建这两种程序。

\subsection*{使用线程的并发编程}

作为并发程序的构建块，大多数编程语言都提供了创建多个独立控制线程的方法。Haskell 也不例外，尽管在 Haskell 中使用线程编程看起来与其他语言有些不同。

Haskell 中，一个线程就是一个独立其它线程执行的\acode{IO}操作。要创建一个线程，我们需要导入\acode{Control.Concurrent}模块并使用\acode{forkIO}函数。

\begin{lstlisting}[language=Haskell]
  ghci> :m +Control.Concurrent
  ghci> :t forkIO
  forkIO :: IO () -> IO ThreadId
  ghci> :m +System.Directory
  ghci> forkIO (writeFile "xyzzy" "seo craic nua!") >> doesFileExist "xyzzy"
  False
\end{lstlisting}

\subsubsection*{线程是不确定的}

GHC 的运行时组件没有指定执行线程的顺序。因此，在上面的示例中，新线程创建的文件\textit{xyzzy}在原始线程检查其存在时可能已经创建，也可能还没有创建。如果我们尝试此
示例一次，然后删除\textit{xyzzy}并再次尝试，那么第二次可能会得到不同的结果。

\subsubsection*{隐藏延迟}

假设有一个很大的文件需要被压缩并写入磁盘，但是又想要迅速的处理用户的输入，使用户感受到程序的快速响应。可以使用\acode{forkIO}在另一个线程中进行文件写入。

\begin{lstlisting}[language=Haskell]
  import Codec.Compression.GZip ( compress )
  import Control.Concurrent (forkIO)
  import Control.Exception (SomeException, handle)
  import qualified Data.ByteString.Lazy as L

  main :: IO ()
  main = do
    putStrLn "Enter a file to compress>"
    name <- getLine
    handle (print :: SomeException -> IO ()) $ do
      content <- L.readFile name
      _ <- forkIO $ compressFile name content
      return ()
    where
      compressFile path = L.writeFile (path ++ ".gz") . compress
\end{lstlisting}

注：原文使用的\acode{readline}库不再适用，另外\acode{print}也需要显式声明类型。

因为这里使用了惰性的\acode{ByteString} I/O，剩下的只需要在主线程中打开文件。实际的读取则是在另一条线程中进行。

\acode{handle print}的使用提供了廉价打印错误信息的方法，例如文件名不存在。

\subsection*{线程间的简单通讯}

在两个线程之间共享信息的最简单方法是让它们都是用一个变量。在我们的文件压缩例子中，主线程与另一个线程共享文件的名称以及内容。因为 Haskell 数据在默认情况下是不可变的，
所以这没有任何的风险：两个线程都不能修改另一个线程所见的文件名或内容。

我们通常需要线程主动地与其他线程进行交互。例如，GHC 并没有为线程提供查看另一个线程是否正在执行、已经完成或是崩溃的方法。不过它提供了一个\textit{同步变量}类型，即
\acode{MVar}，允许我们使用它来达到目的。

\acode{MVar}的作用像是一个单元素的盒子：它要么是满的要么是空的。我们可以将某个东西放入盒子，使其满上，或是拿出使其空置。

\begin{lstlisting}[language=Haskell]
  ghci> import Control.Concurrent
  ghci> :t putMVar
  putMVar :: MVar a -> a -> IO ()
  ghci> :t takeMVar
  takeMVar :: MVar a -> IO a
\end{lstlisting}

如果我们尝试将一个值放入已经满的\acode{MVar}中，线程则会进入睡眠直到其它线程将该值取出。同样的，如果尝试从一个空置的\acode{MVar}中取值，线程也会进入睡眠直到其它的
线程将值放入。

\begin{lstlisting}[language=Haskell]
  import Control.Concurrent

  communicate :: IO ()
  communicate = do
    m <- newEmptyMVar
    _ <- forkIO $ do
      v <- takeMVar m
      putStrLn $ "received" ++ show v
    putStrLn "sending"
    putMVar m "wake up"
\end{lstlisting}

\acode{newEmptyMVar}函数有一个描述性的名称；要创建一个非空的\acode{MVar}则使用\acode{newMVar}。

\begin{lstlisting}[language=Haskell]
  ghci> :t newEmptyMVar
  newEmptyMVar :: IO (MVar a)
  ghci> :t newMVar
  newMVar :: a -> IO (MVar a)
\end{lstlisting}

测试：

\begin{lstlisting}[language=Haskell]
  ghci> :l MVarExample.hs
  [1 of 2] Compiling Main             ( MVarExample.hs, interpreted )
  Ok, one module loaded.
  ghci> communicate
  sending
  received "wake up"
\end{lstlisting}

如果你拥有传统语言中并发编程的经验，那么可以将\acode{MVar}看做是用有两个目的的助力。

\begin{enumerate}
  \item 将一个信息从一个线程发送至另一个线程，例如，消息。
  \item 为线程间共享的可变数据提供\textit{互斥}。当数据没有被任何线程使用时，将其放入\acode{MVar}中，另一个线程将其临时取出进行读取或者修改。
\end{enumerate}

\subsection*{主线程与其它线程的等待}

GHC 的运行时系统将程序的原始控制线程与其它线程区别对待。当该线程完成执行，运行时系统认为程序作为一个整体已经完成。如果又其它线程仍在执行，它们则会被终止。

因此，当我们有不能杀死的长时间运行线程时，我们必须做出特殊安排以确保主线程在其他线程完成之前不会完成。下面是一个小库使其易于实现：

\begin{lstlisting}[language=Haskell]
  import Control.Concurrent
  import Control.Exception
  import Control.Monad
  import Data.Map as M

  data ThreadStatus
    = Running
    | Finished -- terminated normally
    | Threw IOException -- changed from `Exception`
    deriving (Eq, Show)

    -- | Create a new thread manager.
    newManager :: IO ThreadManager

    -- | Create a new managed thread.
    forkManaged :: ThreadManager -> IO () -> IO ThreadId

    -- | Immediately return the status of a managed thread.
    getStatus :: ThreadManager -> ThreadId -> IO (Maybe ThreadStatus)

    -- | Block until a specific managed thread terminates.
    waitFor :: ThreadManager -> ThreadId -> IO (Maybe ThreadStatus)

    -- | Block until all managed threads terminate.
    waitAll :: ThreadManager -> IO ()
\end{lstlisting}

我们使用通常的方法来保持\acode{ThreadManager}类型的抽象：我们将其包装在\acode{newtype}中，并防止用于创建该类型的值。在模块导出中，给出类型构造函数以及
构造管理者的 IO 操作，并不导出数据构造函数。

\begin{lstlisting}[language=Haskell]
  module NiceFork
    ( ThreadManager,
      newManager,
      forkManaged,
      getStatus,
      waitFor,
      waitAll,
    )
  where
\end{lstlisting}

对于\acode{ThreadManager}的实现，我们维护一个从线程 ID 到线程状态的映射：

\begin{lstlisting}[language=Haskell]
  -- Thread map
  newtype ThreadManager
    = Mgr (MVar (M.Map ThreadId (MVar ThreadStatus)))
    deriving (Eq)

  -- Create a new thread manager
  newManager :: IO ThreadManager
  newManager = Mgr <$> newMVar M.empty
\end{lstlisting}

这里有两个级别的\acode{MVar}使用。首先是\acode{Map}，通过替换一个新版本允许我们对其进行“修改”。同时还可以确保使用\acode{Map}的任何线程看到的是一致的视图。

对于管理的每个线程，我们维护一个\acode{MVar}。每个线程的\acode{MVar}开始时为空，即表明线程正在执行。当线程结束或被未捕获的异常杀死时，将该信息放入\acode{MVar}中。

要创建一个线程并观察其状态，我们必须执行一点记录性的操作。

\begin{lstlisting}[language=Haskell]
  -- Create a new managed thread and watch its status
  forkManaged :: ThreadManager -> IO () -> IO ThreadId
  forkManaged (Mgr mgr) body =
    -- safely modify an MVar
    modifyMVar mgr $ \m -> do
      state <- newEmptyMVar
      tid <- forkIO $ do
        result <- try body
        putMVar state $ either Threw (const Finished) result
      return (M.insert tid state m, tid)
\end{lstlisting}

\subsubsection*{安全的修改 MVar}

在上述\acode{forkManaged}中使用的\acode{modifyMVar}函数非常有用：它是一个安全的\acode{takeMVar}与\acode{putMVar}组合。

\begin{lstlisting}[language=Haskell]
  ghci> :t modifyMVar
  ved "wake up!"
  modifyMVar :: MVar a -> (a -> IO (a, b)) -> IO b
\end{lstlisting}

它从\acode{MVar}中取值，将其传递给一个函数。该函数可以同时生成一个新值并返回一个结果。如果该函数抛出异常，那么\acode{modifyMVar}则会将原有值放回\acode{MVar}中，
否则将新值放入其中。它返回函数的另一个元素作为自己的结果。

当我们使用\acode{modifyMVar}而不是通过\acode{takeMVar}与\acode{putMVar}来手动管理一个\acode{MVar}时，我们避免了两种常见的并行错误：

\begin{enumerate}
  \item 忘记将值放回\acode{MVar}。这可能导致\textit{死锁}，在这种情况下，一些线程永远在等待一个永远不会向其放入值的\acode{MVar}。
  \item 未能考虑到抛出异常的可能，从而中断了代码流程。这可能导致\textit{应该}发生的对\acode{putVar}的调用实际上并没有发生，从而再次导致死锁。
\end{enumerate}

因为这些优秀的安全属性，尽可能的使用\acode{mofigyMVar}是一个明智的选择。

我们可以采用\acode{modifyMVar}遵循的模式，将其应用于许多其它资源管理的情况中。以下是该模式的步骤：

\begin{enumerate}
  \item 获取资源
  \item 将资源传递给函数进行处理
  \item 总是释放资源，即使该函数抛出了异常。如果出现这种情况，将异常重新抛出使其能被应用代码捕获。
\end{enumerate}

除了安全之外，这种方法还有另一个好处：它可以使我们的代码更简短且更容易理解。从上面的\acode{forkManaged}中可以看出，Haskell 对于匿名函数的轻量级语法使得这种风格的
编码在视觉上不那么突兀。

以下是\acode{modifyMVar}的定义，我们可以看到这种模式的特定样式：

\begin{lstlisting}[language=Haskell]
  import Control.Concurrent (MVar, putMVar, takeMVar)
  import Control.Exception (evaluate, mask, onException)

  modifyMVar' :: MVar a -> (a -> IO (a, b)) -> IO b
  modifyMVar' m io =
    mask $ \restore -> do
      a <- takeMVar m
      (a', b) <- restore (io a >>= evaluate) `onException` putMVar m a
      putMVar m a'
      return b
\end{lstlisting}

注：详见\href{https://hackage.haskell.org/package/ghc-internal-9.1001.0/docs/src/GHC.Internal.Control.Concurrent.MVar.html#modifyMVar}{此处}。

无论是在处理网络连接、数据库句柄还是 C 库管理的数据，它都能轻松的适应用户的特定需求。

\subsubsection*{查找线程的状态}

\acode{getStatus}函数能告诉我们一个线程的当前状态。如果该线程不再被管理（或者是从来没有被管理过），它返回\acode{Nothing}。

\begin{lstlisting}[language=Haskell]
  -- Immediately return the status of a managed thread
  getStatus :: ThreadManager -> ThreadId -> IO (Maybe ThreadStatus)
  getStatus (Mgr mgr) tid =
    modifyMVar mgr $ \m ->
      case M.lookup tid m of
        Nothing -> return (m, Nothing)
        Just st -> tryTakeMVar st >>= mst m
    where
      mst m' mm = case mm of
        Nothing -> return (m', Just Running)
        Just sth -> return (M.delete tid m', Just sth)
\end{lstlisting}

如果线程仍在运行，其返回\acode{Just Running}。否则，它表示该线程为何被终结，同时停止管理该线程。

如果\acode{tryTakeMVar}函数找到\acode{MVar}是空的，它便立刻返回\acode{Nothing}而不是阻塞。

\begin{lstlisting}[language=Haskell]
  ghci> :t tryTakeMVar
  tryTakeMVar :: MVar a -> IO (Maybe a)
\end{lstlisting}

否则，它像通常那样从\acode{MVar}中提取值。

\acode{waitFor}函数的行为类似，不过并不是立刻返回，它会阻塞，直到给定的线程在返回之前终止。

\begin{lstlisting}[language=Haskell]
  -- Block until a specific managed thread terminates
  waitFor :: ThreadManager -> ThreadId -> IO (Maybe ThreadStatus)
  waitFor (Mgr mgr) tid = do
    maybeDone <- modifyMVar mgr $ \m ->
      return $ case M.updateLookupWithKey (\_ _ -> Nothing) tid m of
        (Nothing, _) -> (m, Nothing)
        (done, m') -> (m', done)
    case maybeDone of
      Nothing -> return Nothing
      Just st -> Just <$> takeMVar st
\end{lstlisting}

它首先提取保存线程状态的\acode{MVar}（如果存在）。\acode{Map}类型的\acode{updateLookupWithKey}函数很有用：它将查找与修改或删除值结合起来。

\begin{lstlisting}[language=Haskell]
  ghci> :m +Data.Map
  ghci> :t updateLookupWithKey
  updateLookupWithKey :: (Ord k) =>
                         (k -> a -> Maybe a) -> k -> Map k a -> (Maybe a, Map k a)
\end{lstlisting}

这种情况下，我们希望总是删除持有线程状态的\acode{MVar}（如果它存在），这样我们的线程管理器将不再管理线程。如果有要提取的值，我们从\acode{MVar}中获取线程的退出状态
并返回它。

最后一个有用的函数就是简单的等待所有管理的线程完成，并忽略它们的退出状态：

\begin{lstlisting}[language=Haskell]
  -- Block until all managed threads terminate
  waitAll :: ThreadManager -> IO ()
  waitAll (Mgr mgr) = modifyMVar mgr es >>= mapM_ takeMVar
    where
      es m = return (M.empty, M.elems m)
\end{lstlisting}

\subsubsection*{编写更紧凑的代码}

上面\acode{waitFor}的定义不太令人满意，因为两个地方执行了类似的代码：在由\acode{modifyMVar}调用的函数内部，以及在它的返回值上。

当然，我们可以应用前面遇到的一个函数来消除这种重复。由\acode{Control.Monad}模块带来的\acode{join}可以解决这个问题。

\begin{lstlisting}[language=Haskell]
  ghci> :m +Control.Monad
  ghci> :t join
  join :: (Monad m) => m (m a) -> m a
\end{lstlisting}

这里的技巧就是通过让第一个表达式返回应该从\acode{modifyMVar}返回后执行的 IO 操作来摆脱第二个\acode{case}表达式。这里使用了\acode{join}：

\begin{lstlisting}[language=Haskell]
  waitFor (Mgr mgr) tid =
    join . modifyMVar mgr $ \m -> return $
      case M.updateLookupWithKey (\_ _ -> Nothing) tid m of
        (Nothing, _) -> (m, return Nothing)
        (Just st, m') -> (m', Just <$> takeMVar st)
\end{lstlisting}

这是一个有趣的想法：我们可以在纯函数代码中创建 monadic 函数或操作，然后传递它，直到最终可用的单元中结束。一旦我们的开发令其有意义，这可能是一种灵活的编写代码的方式。

\subsection*{通过隧道进行交流}

对于线程之间的一次性通信，\acode{MVar}是非常好的选择。另一种类型\acode{Chan}提供单向通信通道。下面是一个简单的例子：

\begin{lstlisting}[language=Haskell]
  import Control.Concurrent (forkIO, newChan, readChan, writeChan)

  chanExample :: IO ()
  chanExample = do
    ch <- newChan
    _ <- forkIO $ do
      writeChan ch "hello world"
      writeChan ch "now i quit"
    readChan ch >>= print
    readChan ch >>= print
\end{lstlisting}

如果\acode{Chan}是空的，\acode{readChan}会阻塞知道有值可以读取。\acode{writeChan}函数永远不会阻塞：它会立刻向\acode{Chan}中写入一个新值。

\subsection*{几点重要的须知}

\subsubsection*{MVar 与 Chan 是 non-strict 的}

正如大多数 Haskell 容器类型一样，\acode{MVar}与\acode{Chan}都是 non-strict 的：它们都不计算其内容。提到这点并不是因为它是一个问题，而是因为它是一个常见的盲点：
人们倾向认为这些类型是 strict 的，也许是因为它们在\acode{IO}单子中使用。

对于其它容器类型，错误猜测\acode{MVar}或\acode{Chan}类型的 strict 性的结果通常是空间或性能泄漏。这里有一个合理的设想。

fork 一个线程，在另一个核执行昂贵计算。

\begin{lstlisting}[language=Haskell]
  import Control.Concurrent

  notQuiteRight :: IO ()
  notQuiteRight = do
    mv <- newEmptyMVar
    _ <- forkIO $ expensiveComputation_stricter mv
    -- some other activity
    result <- takeMVar mv
    print result

  expensiveComputation_stricter :: MVar [Char] -> IO ()
  expensiveComputation_stricter mv = do
    let a = "this is"
        b = "not really"
        c = "all that expensive"
    putMVar mv (a ++ b ++ c)
\end{lstlisting}

这像是做某事儿，同时将其结果返回给\acode{MVar}：

\begin{lstlisting}[language=Haskell]
  expensiveComputation_stricter :: MVar [Char] -> IO ()
  expensiveComputation_stricter mv = do
    let a = "this is"
        b = "not really"
        c = "all that expensive"
    putMVar mv (a ++ b ++ c)
\end{lstlisting}

当我们从父线程的\acode{MVar}中获取结果并试图对它做一些事情时，我们的线程开始疯狂的计算，因为我们从未强迫计算发生在另一个线程内！

像往常一样，解决方案很简单，一旦我们知道存在潜在的问题：为 fork 的线程增加 strict 性，以确保计算在原线程发生。strict 最好放在一个地方，以免遗忘。

\begin{lstlisting}[language=Haskell]
  {-# LANGUAGE BangPatterns #-}

  import Control.Concurrent (MVar, putMVar, takeMVar)
  import Control.Exception (IOException, catch, mask, onException, throw)

  modifyMVar_strict :: MVar a -> (a -> IO a) -> IO ()
  modifyMVar_strict m io = mask $ \restore -> do
    a <- takeMVar m
    !a' <- restore (io a) `onException` putMVar m a
    putMVar m a'

  modifyMVar_strict' :: MVar a -> (a -> IO a) -> IO ()
  modifyMVar_strict' m io = mask $ \restore -> do
    a <- takeMVar m
    !a' <-
      restore (io a) `catch` \e ->
        putMVar m a >> throw (e :: IOException)
    putMVar m a'
\end{lstlisting}

注：原文中\acode{Control.Exception}库提供的\acode{block}与\acode{unblock}已被废弃，现在改用\acode{mask}来实现。

上述代码中的\acode{!}模式简单易用，但这并不总保证数据总能被计算。

\subsubsection*{Chan 是无边界的}

由于\acode{writeChan}总能立即成功，所以使用\acode{Chan}有着潜在的风险。如果一个线程的写比另一个线程的读要多，那么这个线程将以一种不受约束的方式增长：未读的消息
将随着读取越来越落后而堆积起来。

\subsection*{共享状态仍然很困难}

尽管与其它语言相比，Haskell 在线程间共享数据有不同的原语，但它仍然面临相同的基本问题：编写正确的并发程序非常困难。实际上，其它语言中并发编程的一些缺陷同样适用
于 Haskell。两个比较著名的问题就是\textit{死锁}与\textit{饥饿}。

\subsubsection*{死锁}

在\textit{死锁}的情况下，两个或多个线程在访问共享资源时永远的卡住。一个典型的多线程死锁问题就是忘记申请锁的顺序。这类型的 bug 太常见了，即：\textit{锁序反转}。
虽然 Haskell 不提供锁，但是\acode{MVar}类型仍然容易出现顺序反转的问题。下面是一个简单的例子：

\begin{lstlisting}[language=Haskell]
  import Control.Concurrent (MVar, forkIO, modifyMVar_, newMVar, yield)

  nestedModification :: (Num a1, Num a2) => MVar a2 -> MVar a1 -> IO ()
  nestedModification outer inner = do
    modifyMVar_ outer $ \x -> do
      yield -- force this thread to temporarily yield the CPU
      modifyMVar_ inner $ \y -> return $ y + 1
      return $ x + 1
    putStrLn "done"

  main :: IO ()
  main = do
    a <- newMVar (1 :: Int)
    b <- newMVar (2 :: Int)
    _ <- forkIO $ nestedModification a b
    _ <- forkIO $ nestedModification b a

    return ()
\end{lstlisting}

如果将此运行在\textbf{ghci}中，通常（并不总是）打印不了任何东西，这表明两个线程都被卡住了。

\acode{nestedModification}函数的问题很容易发现。在第一个线程中，我们取\acode{MVar a}，接着取\acode{b}；在第二个线程中，我们取\acode{b}然后取\acode{a}。
如果第一个线程成功取到了\acode{a}，第二个线程取\acode{b}，两个线程都将阻塞：每个线程都试图取另一个线程已经清空了的\acode{MVar}，所以两个线程都不会有进展。

各种语言中，解决顺序反转的常用方法是在获取资源时始终遵循一致的顺序。由于这种方法需要手动遵循编码约定，因此在实践中很容易被忽略。

更复杂的是，这些反转问题在实际代码很难被发现。\acode{MVar}的获取通常分布在不同文件中的若干函数中，这使得肉眼检测变得更加棘手。更糟糕的是，这些问题往往是
\textit{间歇性的}，这让它们变得很难复现，更不用说隔离和修复了。

\subsubsection*{饥饿}

并发软件也很容易出现\textit{饥饿}，即一个线程“霸占”共享资源，阻止另一个线程使用它。很容易想象这是如何发生的：一个线程用执行 100 毫秒的主体调用\acode{modifyMVar}，
而另一个线程用执行 1 毫秒的主体在同一个\acode{MVar}上调用\acode{modifyMVar}。在第一个线程将一个值放回\acode{MVar}之前，第二个线程无法取得任何进展。

\acode{MVar}类型的 non-strict 性质可能加剧或导致饥饿问题。如果我们在\acode{MVar}中放入一个计算成本很高的东西，然后把它从\acode{MVar}中取出，放到一个看起来很
轻量的线程中，那么这个线程就会突然变得高计算成本，因为它必须计算这个东西。

\subsubsection*{还有任何的希望吗？}

幸运的是，在这里介绍的用于并发性的 api 并不是结局。Haskell 有一个名为软件事务性内存的功能，使用起来更容易也更安全。我们将会在第二十八中进行讨论。

\subsection*{使用多核 GHC}

默认情况下，GHC 生成的程序只使用一个内核，即使我们显式的编写并发代码也是如此。要使用多核，我们必须明确的选择这样做。在生成可执行程序时，我们在链接时做出此选择。

\begin{itemize}
  \item “非线程”运行库在单个操作系统线程中运行所有的 Haskell 线程。这个运行时对于\acode{MVar}中创建线程和传递数据非常高效。
  \item “线程”运行库使用多个操作系统线程来运行 Haskell 线程。它在创建线程和使用\acode{MVar}方面有更多的开销。
\end{itemize}

如果我们将\acode{-thread}选项传递给编译器，它将把我们的程序链接到线程运行时库。在编译库或源文件时不需要使用\acode{-thread}，只有在最终生成可执行文件时才需要使用
\acode{-thread}。

即使我们为程序选择了线程运行时，当我们运行它时，它仍然默认只使用一个内核。我们必须明确的告诉运行时要使用多少内核。

\subsubsection*{运行时选项}

我们可以在程序的命令行上将选项传递给 GHC 的运行时系统。在将控制权交给代码之前，运行时扫描程序的参数，以查找特殊的命令行选项\acode{+RTS}。它将之后的所有内容，直到特殊
选项\acode{-RTS}，解释为运行时系统的选项，而不是我们的程序。它在代码中隐藏了所有这些选项。当我们使用\acode{System.Environment}模块的\acode{getArgs}函数来
获取我们的命令行参数，我们不会在列表中找到任何运行时选项。

线程运行时接受一个选项\acode{-N}。它有一个参数，指定\acode{GHC}运行时系统应该使用的内核数量。选项解析器是挑剔的：\acode{-N}和后面的数字之间不能有空格。选项
\acode{-N4}是可以接受的，而\acode{-N 4}则不行。

\subsubsection*{为 Haskell 寻找有效核术}

\acode{GHC.Conc}模块导出了一个变量，\acode{numCapabilities}，可以告诉我们运行时系统通过\acode{-N} RTS 选项分配了多少核数。

\begin{lstlisting}[language=Haskell]
  import GHC.Conc (numCapabilities)
  import System.Environment (getArgs)

  main :: IO ()
  main = do
    args <- getArgs
    putStrLn $ "command line arguments: " <> show args
    putStrLn $ "number of cores: " <> show numCapabilities
\end{lstlisting}

如果编译并运行上述程序，就可以看到运行时的选项在程序中并不可见，但是可以看到多少核可以用于运行。

\begin{lstlisting}[language=Haskell]
  $ ghc -c NumCapabilities.hs
  $ ghc -threaded -o NumCapabilities NumCapabilities.o
  $ ./NumCapabilities +RTS -N4 -RTS foo
  command line arguments: ["foo"]
  number of cores: 4
\end{lstlisting}

\subsubsection*{使用合适的运行时}

使用哪个运行时的决定并不完全明确。虽然线程运行时可以使用多个内核，但它有一个代价：线程和在它们之间共享数据比使用非线程运行时更昂贵。

在许多现实世界的并发程序中，单个线程将花费大部分时间等待网络请求或响应。这些情况下，如果一个 Haskell 程序为成千上万个并发客户提供服务，那么非线程运行时的较低开销可能
会有所帮助。例如，与其让单个服务器程序在四个核上使用线程运行时，不如将服务器设计成可以同时运行它的四个副本，并使用非线程运行时。如此可能会得到更好的性能。

\subsection*{Haskell 中的并行编程}

现在我们将重点转向并行编程。对于许多计算成本很高的问题，如果我们可以将解决方案分离，并同时在多个核上进行计算，那么就可以更快的计算出结果。

\subsubsection*{Normal form 以及 head normal form}

熟知的\acode{seq}函数将表达式求值为我们所说的头范式（缩写 HNF）。它一旦到达最外层的构造函数（“头部”）就会停止。这与正常范式（NF）不同，在正常范式（NF）中，表达式
是完全求值的。

我们还会听到 Haskell 程序员提到的弱头范式（WHNF）。对于正常数据，若头正常范式与头正常范式相同。这种差别只出现在函数上，不过这过于深奥了，在这里不进行讨论。

\subsubsection*{序列化排序}

以下是一个使用分治方法的普通 Haskell 函数，其用于列表排序。

\begin{lstlisting}[language=Haskell]
  -- divide-and-conquer
  sort :: (Ord a) => [a] -> [a]
  sort (x : xs) = lesser ++ x : greater
    where
      lesser = sort [y | y <- xs, y < x]
      greater = sort [y | y <- xs, y >= x]
  sort _ = []
\end{lstlisting}

这个函数的灵感来源于著名的快排算法，它是 Haskell 程序员中的经典：它经常在 Haskell 教程的早期以一行代码的形式出现，用 Haskell 的表达性来戏弄读者。这里，我们将代码
分成几行，以便于比较串行与并行的版本。

下面是\acode{sort}操作的简单介绍：

\begin{enumerate}
  \item 它从列表中选择一个元素。这被称为\textit{轴心点 pivot}。任何元素都可以是轴心点；第一种模式是最容易匹配的。
  \item 它为小于轴心点的所有元素创建一个子列表，并对它们进行递归排序。
  \item 它为大于或等于轴心点的所有元素创建一个子列表，并对它们进行递归排序。
  \item 合并两个排序好的子列表。
\end{enumerate}

\subsubsection*{转换代码为并行代码}

并行版本的函数比初版稍微复杂了一些：

\begin{lstlisting}[language=Haskell]
  import Control.Parallel (par, pseq)

  parSort :: (Ord a) => [a] -> [a]
  parSort (x : xs) = force greater `par` (force lesser `pseq` (lesser ++ x : greater))
    where
      lesser = parSort [y | y <- xs, y < x]
      greater = parSort [y | y <- xs, y >= x]
  parSort _ = []
\end{lstlisting}

我们几乎没有扰乱代码：我们所添加的只是三个函数，\acode{par}，\acode{pseq}以及\acode{force}。

\acode{par}函数由\acode{Control.Parallel}模块提供。它的左右与\acode{seq}类似：将左参求值为弱头范式，并返回右参。顾名思义，\acode{par}可以与正在发生的任何
其它求值并行的求其左参。

至于\acode{pseq}，它与\acode{seq}类似：先将左边的表达式求值为 WHNF，然后返回右边的表达式。两者之前的区别很微妙，但对于并行程序而言很重要：如果编译器看到先求右参会
提高性能，则不会\textit{承诺}求\acode{seq}的左参。这种灵活性对于在一个核上执行的程序而言很好，但是对于在多个核上运行的代码而言就不够强劲了。相反编译器\textit{保证}
\acode{pseq}会先求左参，再求右参。

这些对于我们代码的修改而言是值得关注的，因为我们不需要说明所有的事情。

\begin{itemize}
  \item 使用多少核
  \item 什么线程用于彼此间的通讯
  \item 如何在可用核中拆分任务
  \item 什么数据是线程间共享的，什么是私有的
  \item 所有部分完成后如何收尾
\end{itemize}

\subsubsection*{知道并行计算什么}

从并行 Haskell 代码中获得良好性能的关键是找到有意义的工作块来并行执行。Non-strict 的计算会妨碍到这点，这就是在并行排序中使用\acode{force}函数的原因。为了更好的
解释\acode{force}函数的作用，我们先来看一个错误的例子：

\begin{lstlisting}[language=Haskell]
  sillySort :: (Ord a) => [a] -> [a]
  sillySort (x : xs) = greater `par` (lesser `pseq` (lesser ++ x : greater))
    where
      lesser = sillySort [y | y <- xs, y < x]
      greater = sillySort [y | y <- xs, y >= x]
  sillySort _ = []
\end{lstlisting}

看一下每个使用\acode{par}处的小改变。没有用\acode{force lesser}与\acode{force greater}，而是直接计算\acode{lesser}与\acode{greater}。

请记住，对 WHNF 的求值只计算足以查看其最外层构造函数的表达式。这个错误示例中，我们将每个排序的子列表求值为 WHNF。由于每种情况下最外层的构造函数都只是一个列表构造函数，
因此我们实际上只强制对每个排序子列表的第一个元素求值！每个列表的其它所有元素保持未求值。换言之，几乎没有并行的做任何有用的工作：\acode{sillySort}几乎是完全顺序的。

我们通过\acode{force}函数强制整个列表，在返回给构造函数之前进行计算，避免上述情况发生：

\begin{lstlisting}[language=Haskell]
  force :: [a] -> ()
  force xs = go xs `pseq` ()
    where
      go :: [a] -> Integer
      go (_ : xs') = go xs'
      go [] = 1
\end{lstlisting}

注意我们并不在乎列表中的是什么；我们遍历列表至最后，使用\acode{pseq}。这里显然没有魔法：只是使用我们对 Haskell 计算模型的理解。又因为我们将在\acode{par}或
\acode{pseq}的左侧使用\acode{force}，我们不需要返回一个有意义的值。

当然很多情况下，我们也需要强制对列表中的单个元素求值。下面，我们将讨论这个问题的基于类型的解决方案。

\subsubsection*{par 做了什么承诺}

\acode{par}函数实际上并没有保证一个表达式与另一个表达式并行求值。相反，它承诺如果这样做“有意义”才会这么做。这种模棱两可的不承诺实际上比总是并行求值表达式的保证更有用。
它使运行时系统在遇到\acode{par}的使用时可以自由的采取智能行动。

例如，运行时可能会认为表达式太廉价而不值得并行计算，或者它可能会注意到所有内核当前都很忙，因此“触发”一个新的并行计算将导致可运行线程的数量超过可执行的内核数量。

这种松散的规范反过来又影响了我们编写并行代码的方式。由于\acode{par}在运行时可能有点智能，我们几乎可以在任何喜欢的地方使用它，假设性能不会因为线程争用繁忙的内核而陷入
困境。

\subsubsection*{允许代码并测量性能}

为了测试代码，让我们将\acode{sort}，\acode{parSort}与\acode{parSort2}保存到一个名为\acode{Sorting.hs}的模块中。我们创建了一个小的驱动程序，我们可以使用它
来计时其中一个排序函数的性能。

\begin{lstlisting}[language=Haskell]

  module Main where

  import Data.Time.Clock
  import qualified Sorting as S
  import System.Environment (getArgs)
  import System.Random

  testFunction :: Int -> [Int] -> [Int]
  testFunction n
    | n == 1 = S.sort
    | n == 2 = S.parSort
    | n == 3 = S.seqSort
    | n == 4 = S.parSort2 100000 -- temporary used input
    | otherwise = error "choose n from 1 to 4"

  randomInts :: Int -> StdGen -> [Int]
  randomInts k g =
    let result = take k (randoms g)
     in S.force result `seq` result

  -- test:
  -- cabal run sort-main 3 500000
  main :: IO ()
  main = do
    args <- getArgs

    case args of
      (sortMethod : count : _) -> do
        input <- randomInts (read count) `fmap` getStdGen
        putStrLn $ "We have " ++ show (length input) ++ " elements to sort."
        start <- getCurrentTime
        let sorted = testFunction (read sortMethod) input
        putStrLn $ "Sorted all " ++ show (length sorted) ++ " elements."
        end <- getCurrentTime
        putStrLn $ show (end `diffUTCTime` start) ++ " elapsed."
      _ -> error "SortMain <sortMethod:Int> <count:Int>"
\end{lstlisting}

简单起见，我们通过\acode{testFunction}变量选择在编译时进行基准测试的排序函数。

我们的程序接受一个可选的命令行参数，即要生成的随机列表的长度。

Non-strict 的计算会把性能测量和分析变成雷区。这里有一些潜在的问题，需要我们避免在我们的驱动程序中出现。

\begin{itemize}
  \item \textit{当我们认为在看待一件事物时，实际上却要衡量几件事。}Haskell 的默认伪随机数生成器（PRNG）很慢，\acode{random}函数根据需要生成随机数。

        在记录开始时间之前，我们强制计算列表中的每个元素，并打印列表的长度：这确保我们提前创建了所有需要的随机数。

        如果我们省略这一步，那么将把随机数的生成与并行处理随机数交织在一起。因此，既要测量排序数字的成本，也要测量生成数字的成本（不太明显）。

  \item \textit{不可见的数据依赖。}当我们生成随机数列表时，简单的打印列表的长度将无法执行足够的求值。这将计算列表的主体，而不是其元素。实际的随机数在排序比较它们之前
        不会被计算。

        这可能会对性能产生严重的影响。随机数的值取决于列表中前面随机数的值，但是我们在处理器内核中随机分散了列表元素。如果我们在排序之前没有对列表元素进行计算，那么
        我们将遭受可怕的“乒乓”效应：计算不仅会从一个核跳到另一个核，性能也会受到影响。

        试着从上面的\acode{main}主体中去掉\acode{force}的应用：我们会发现并行代码很容易比非并行代码\textit{慢}三倍。

  \item \textit{当我们相信代码正在执行有意义的工作时，基准测试是一种思考。}为了强制进行排序，在记录结束时间之前打印结果列表的长度。如果没有\acode{putStrLn}要求
        列表的长度来打印它，那么排序就根本不会发生。
\end{itemize}

当我们构建程序时，我们启用了优化和 GHC 的线程运行时。

\begin{lstlisting}[language=Haskell]
  ghc -threaded -O2 -package parallel -package time --make SortMain
  Loaded package environment from /Users/jacobxie/.ghc/aarch64-darwin-9.8.2/environments/default
  [1 of 3] Compiling Sorting          ( Sorting.hs, Sorting.o )
  [2 of 3] Compiling Main             ( SortMain.hs, SortMain.o )
  [3 of 3] Linking SortMain
\end{lstlisting}

注：也可以通过 cabal 或 stack 配置，以下是 cabal 设置：

\begin{lstlisting}
  executable sort-main
  import:           warnings
  default-language: Haskell2010
  main-is:          SortMain.hs
  ghc-options:      -threaded -O2
  build-depends:
    , base
    , my-concurrent
    , parallel
    , random
    , time
\end{lstlisting}

当我们运行程序时，必须告诉 GHC 的运行时需要使用多少内核。开始我们尝试原始排序

\begin{lstlisting}[language=Bash]
  # 使用 GHC 编译后的可执行文件
  ./SortMain +RTS -N1 -RTS 1 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  10.959195s elapsed.

  # 或者使用 cabal
  cabal run sort-main +RTS -N1 -RTS 1 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  10.884864s elapsed.
\end{lstlisting}

注：与原文不同，\acode{SortMain.hs}改造后的第一个 arg 为 1 时，为单线程运行；为 2 时，为并行运行。

启用第二个核并不会太影响效率。

\begin{lstlisting}[language=Haskell]
  ./SortMain +RTS -N2 -RTS 1 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  11.082317s elapsed.
\end{lstlisting}

接下来试试\acode{parSort}，结果并不理想。

\begin{lstlisting}[language=Haskell]
  cabal run sort-main +RTS -N1 -RTS 2 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  13.192825s elapsed.

  cabal run sort-main +RTS -N2 -RTS 2 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  12.038354s elapsed.
\end{lstlisting}

我们在效率上毫无提高，这可能是由于以下两个因素之一：要么\acode{par}本身就很昂贵，要么是我们使用的太多了。为了区分这两种可能性，这里有一个与\acode{parSort}相同的
排序，使用\acode{pseq}而不是\acode{par}。

\begin{lstlisting}[language=Haskell]
  seqSort :: (Ord a) => [a] -> [a]
  seqSort (x:xs) = lesser `pseq` (greater `pseq` (lesser ++ x:greater))
    where
      lesser = seqSort [y | y <- xs, y < x]
      greater = seqSort [y|y <- xs, y >= x]
  seqSort _ = []
\end{lstlisting}

我们也放弃了使用\acode{force}，所以与最初的\acode{sort}相比，我们应该只测量使用\acode{pseq}的成本。单独的\acode{pseq}对性能有什么影响？

\begin{lstlisting}[language=Haskell]
  cabal run sort-main +RTS -N1 -RTS 3 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  12.348779s elapsed.
\end{lstlisting}

这说明\acode{par}与\acode{pseq}的成本相似。该怎么样提高性能呢？

\subsubsection*{性能调优}

在\acode{parSort}中，执行的\acode{par}应用程序数量是要排序的元素数量的两倍。虽然\acode{par}很\textit{廉价}，但是它并不是免费的。当递归的应用\acode{parSort}
时，最终会对单个列表元素应用\acode{par}。在这种细颗粒度下，使用\acode{par}的成本超过了任何可能的有用性。为了减少这种影响，我们在超过某个阈值后切换到非并行排序。

\begin{lstlisting}[language=Haskell]
  parSort2 :: (Ord a) => Int -> [a] -> [a]
  parSort2 d lst@(x : xs)
    | d <= 0 = sort lst
    | otherwise = force greater `par` (force lesser `pseq` (lesser ++ x : greater))
    where
      lesser = parSort2 d' [y | y <- xs, y < x]
      greater = parSort2 d' [y | y <- xs, y >= x]
      d' = d - 1
  parSort2 _ _ = []
\end{lstlisting}

这里，我们停止递归并在可控深度触发新的并行计算。如果我们知道正在处理的数据大小，那么就可以停止细分并在剩余工作量足够小时切换到非并行代码。

\begin{lstlisting}[language=Bash]
  ghc -threaded -O2 -package parallel -package time --make SortMain

  ./SortMain +RTS -N2 -RTS 4 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  7.802378s elapsed.
\end{lstlisting}

注：\acode{testFunction}的函数体中\acode{S.parSort2 100000}参数并不是最优。

略。

\subsection*{并行策略以及 MapReduce}

编程社区中，最受函数式编程启发的著名软件系统之一是 Google 的 MapReduce 基础设施，用于并行处理大量数据。

虽然我们可以创建一个简单的实现而不需耗费太多的努力，但是我们需要抵制这个诱惑。如果考虑解决一类问题而不是单个问题，我们可能会得到更广泛适用的代码。

\begin{itemize}
  \item 我们的算法很快就会被划分与通信的细节所掩盖。这使得理解代码变得困难，这反过来又使得修改代码变得危险。
  \item 选择一个“颗粒大小” -- 分配到一个核的最小工作单元 -- 是很困难的。如果颗粒度太小，内核则要花费大量时间进行记录，因此并行程序很容易变得比串行慢。如果颗粒度
        过大，可能会导致部分内核因负载不均衡而处于空闲状态。
\end{itemize}

\subsubsection*{从计算中分离算法}

在并行的 Haskell 代码中，传统语言中通信代码产生的混乱被\acode{par}与\acode{pseq}所取代。例如，以下的函数操作类似于\acode{map}，但在执行时并行的将每个元素求值
为弱头范式（WHNF）。

\begin{lstlisting}[language=Haskell]
  import Control.Parallel

  parallelMap :: (a -> b) -> [a] -> [b]
  parallelMap f (x : xs) = let r = f x in r `par` r : parallelMap f xs
  parallelMap _ _ = []
\end{lstlisting}

类型\acode{b}可能是一个列表，或者其它类型，对\acode{WHNF}的求值不会做大量有用的工作。我们希望不必为列表和其他需要特殊处理的类型编写特殊的\acode{parallelMap}。

为了解决这个问题，我们将从考虑一个更简单的问题开始：如何强制求值。下面是一个函数，它强制将列表中的每个元素求值为 WHNF。

\begin{lstlisting}[language=Haskell]
  forceList :: [a] -> ()
  forceList (x:xs) = x `pseq` forceList xs
  forceList _ = ()
\end{lstlisting}

我们的函数不对列表执行任何计算。（事实上，通过检查它的类型签名，我们可以知道它不能执行任何计算，因为它对列表的元素一无所知。）其唯一目的是确保列表被计算为头范式。应用
这个函数唯一有意义的地方是\acode{seq}或\acode{par}的第一个参数，例如如下所示：

\begin{lstlisting}[language=Haskell]
  stricterMap :: (a -> b) -> [a] -> [b]
  stricterMap f xs = forceList xs `seq` map f xs
\end{lstlisting}

这仍然给我们留下了只对 WHNF 求值的列表元素。我们通过添加一个函数作为参数来解决这个问题，该函数可以强制对元素进行更深入的求值。

\begin{lstlisting}[language=Haskell]
  forceListAndElts :: (a -> ()) -> [a] -> ()
  forceListAndElts forceElt (x : xs) = forceElt x `seq` forceListAndElts forceElt xs
  forceListAndElts _ _ = ()
\end{lstlisting}

\acode{Control.Parallel.Strategies}模块将这个想法概括为我们可以用做库的东西。它引入了\textit{计算策略}的概念。

\begin{lstlisting}[language=Haskell]
  type Done = ()

  type Strategy a = a -> Done
\end{lstlisting}

求值策略不执行计算；它只是确保一个值在某种程度上被求值。最简单的策略被称为\acode{r0}，它什么都不做。

\begin{lstlisting}[language=Haskell]
  r0 :: Strategy a
  r0 _ = ()
\end{lstlisting}

接下来是\acode{rwhnf}，它计算弱头范式的一个值。

\begin{lstlisting}[language=Haskell]
  rwhnf :: Strategy a
  rwhnf x = x `seq` ()
\end{lstlisting}

为了计算正常范式的一个值，模块提供了一个 typeclass 名为\acode{rnf}的方法。

\begin{lstlisting}[language=Haskell]
  class NFData a where
    rnf :: Strategy a
    rnf = rwhnf
\end{lstlisting}

\begin{anote}
  记住这些名称

  如果记不住这些函数和类型的名称，将它们视为同义词即可。\acode{rwhnf}意为“reduce to weak head normal form”；而\acode{NFData}则是“normal form data”；
  以此类推。
\end{anote}

对于基本类型，比如\acode{Int}，弱头范式和正常范式是一样的，这就是\acode{NFData} typeclass 使用\acode{rwhnf}作为\acode{rnf}的默认实现的原因。对于许多常见
类型，\acode{Control.Parallel.Strategies}模块提供了\acode{NFData}实例。

\begin{lstlisting}[language=Haskell]
  instance NFData Char

  instance NFData Int

  instance (NFData a) => NFData (Maybe a) where
    rnf Nothing = ()
    rnf (Just x) = rnf x

  {- ... and so on ... -}
\end{lstlisting}

从这些实例中，应该可以清楚的看到如何为自己的类型编写\acode{NFData}实例。用户的\acode{rnf}实现必须处理每个构造函数，并将\acode{rnf}应用于构造函数的每个字段。

\subsubsection*{从策略中分离算法}

从这些策略构建块中可以构建更复杂的策略。许多已由\acode{Control.Parallel.Strategies}提供。例如\acode{parList}并行的对列表的每个元素应用求值策略。

\begin{lstlisting}[language=Haskell]
  parList :: Strategy a -> Strategy [a]
  parList _ [] = ()
  parList strat (x : xs) = strat x `par` (parList strat xs)
\end{lstlisting}

该模块使用它来定义并行的\acode{map}函数。

\begin{lstlisting}[language=Haskell]
  parMap :: Strategy b -> (a -> b) -> [a] -> [b]
  parMap strat f xs = map f xs `using` parList strat
\end{lstlisting}

这就是代码变得有趣的地方。在\acode{using}的左侧，有一个普通的\acode{map}应用。右侧则是计算策略。\acode{using}组合子告诉我们如何将策略应用于一个值，允许我们将
代码与计算其的求值方式分离。

\begin{lstlisting}[language=Haskell]
  using :: a -> Strategy a -> a
  using x s = s x `seq` x
\end{lstlisting}

\acode{Control.Parallel.Strategies}模块提供了许多其他函数，这些函数提供了对求值的精细控制。例如，使用求值策略并行应用\acode{zipWith}的\acode{parZipWith}。

\begin{lstlisting}[language=Haskell]
  vectorSum' :: (NFData a, Num a) => [a] -> [a] -> [a]
  vectorSum' = parZipWith rnf (+)
\end{lstlisting}

\subsubsection*{编写一个简单的 MapReduce 定义}

对于一个\acode{mapReduce}函数我们可以快速的了解到其需要的类型。即一个\textit{map}组件，给与它一个通常的类型\acode{a -> b}。同时还需要一个\textit{reduce}；
该项为\textit{fold}的同义词。与其去编写一个特殊类型的 fold，我们将使用一个更泛化的类型，\acode{[b] -> c}。这个类型允许我们是有左或右折叠，这样我们可以选择一个
符合我们数据的再进行处理。

如果我们将这些类型放在一起，那么完全的类型将类似于：

\begin{lstlisting}[language=Haskell]
  simpleMapReduce ::
    (a -> b) -> -- map function
    ([b] -> c) -> -- reduce function
    [a] -> -- list to map over
    c
\end{lstlisting}

函数本身非常的简单：

\begin{lstlisting}[language=Haskell]
  simpleMapReduce mapFunc reduceFunc = reduceFunc . map mapFunc
\end{lstlisting}

\subsubsection*{MapReduce 与策略}

我们\acode{simpleMapReduce}的定义太简单了。要使其变得有用，我们希望能指定某些任务可以并行。通过策略可以达到目的，传入一个\acode{map}的策略以及\acode{reduce}
的策略。

\begin{lstlisting}[language=Haskell]
  mapReduce ::
    Strategy b -> -- evaluation strategy for mapping
    (a -> b) -> -- map function
    Strategy c -> -- evaluation strategy for reduction
    ([b] -> c) -> -- reduce function
    [a] -> -- list to map over
    c
\end{lstlisting}

函数的类型和函数体都需要增大来适应策略参数。

\begin{lstlisting}[language=Haskell]
  mapReduce mapStrat mapFunc reduceStrat reduceFunc input =
    mapResult `pseq` reduceResult
    where
      mapResult = parMap mapStrat mapFunc input
      reduceResult = reduceFunc mapResult `using` reduceStrat
\end{lstlisting}

\subsubsection*{合理规划}

为了获得良好的性能，我们必须确保每个使用\acode{par}的应用都能使用理论的成本。如果是处理一个大文件，通过行切分任务对比任务整体而言只占很小部分的负载。

我们将在之后的小节中开发一种处理大块文件的方式。那么这些大块是由什么构成的呢？一个 web 服务的日志文件应该只包含 ASCII 文本，我们将看到通过惰性的\acode{ByteString}
所带来的优良性能：该类型是高效的，且在流式处理文件时仅消耗少量内存。

\begin{lstlisting}[language=Haskell]
  module LineChunks
    ( chunkedReadWith,
    )
  where

  import Control.Exception (bracket, finally)
  import Control.Parallel.Strategies (NFData, rdeepseq)
  import qualified Data.ByteString.Lazy.Char8 as LB
  import Data.Int (Int64)
  import GHC.Conc (numCapabilities)
  import GHC.IO.Handle (Handle, hClose)

  data ChunkSpec = CS
    { chunkOffset :: !Int64,
      chunkLength :: !Int64
    }
    deriving (Eq, Show)

  withChunks ::
    (NFData a) =>
    (FilePath -> IO [ChunkSpec]) ->
    ([LB.ByteString] -> a) ->
    FilePath ->
    IO a
  withChunks chunkFunc process path = do
    (chunks, handles) <- chunkedRead chunkFunc path
    let r = process chunks
    (rdeepseq r `seq` return r) `finally` mapM_ hClose handles

  chunkedReadWith :: (NFData a) => ([LB.ByteString] -> a) -> FilePath -> IO a
  chunkedReadWith func path =
    withChunks (lineChunks (numCapabilities * 4)) func path

  chunkedRead :: (FilePath -> IO [ChunkSpec]) -> FilePath -> IO ([LB.ByteString], [Handle])
  chunkedRead = undefined

  lineChunks :: Int -> FilePath -> IO [ChunkSpec]
  lineChunks = undefined
\end{lstlisting}

我们并行的消费每个数据块，通过惰性 I/O 的优势确保可以安全的以流的方式，处理这些数据块。

\subsubsection*{降低惰性 I/O 的风险}

惰性 I/O 会带来一些我们希望避免的众所周知的危害。

\begin{itemize}
  \item 通过不强制从文件句柄中提取数据的计算进行评估，我们可以无形的使文件句柄打开的时间超过必要的时间。由于操作系统通常会对一次可以打开的文件数量设置一个小的固定
        限制，如果不解决这个风险，可能会意外的使程序的其它部分缺少文件句柄。
  \item 如果没有显式关闭文件句柄，垃圾收集器将自动为我们关闭它。可能需要很长时间才能注意到应该关闭。这就造成了与上一条一样的饥饿风险。
  \item 我们可以通过显式关闭文件句柄来避免饥饿。但是如果太早这么做，惰性计算期望能够从关闭的句柄中提取更多数据，则会导致惰性计算失败。
\end{itemize}

除了这些众所周知的风险外，我们不能使用单个文件句柄向多线程提供数据。文件句柄有一个单独的“查找指针”来跟踪它应该读取的位置，但是当我们想要读取多个块时，每个块都需要从
文件中的不同位置消费数据。

有了上述这些概念，让我们来填写一下惰性 I/O。

\begin{lstlisting}[language=Haskell]
  chunkedRead :: (FilePath -> IO [ChunkSpec]) -> FilePath -> IO ([LB.ByteString], [Handle])
  chunkedRead chunkFunc path = do
    chunks <- chunkFunc path
    liftM unzip . forM chunks $ \spec -> do
      h <- openFile path ReadMode
      hSeek h AbsoluteSeek (fromIntegral $ chunkOffset spec)
      chunk <- LB.take (chunkLength spec) `liftM` LB.hGetContents h
      return (chunk, h)
\end{lstlisting}

我们通过显式的关闭文件句柄来避免饥饿问题。我们允许多个线程一次读取不同的块，方法是为每个线程提供一个不同的文件句柄，所有线程读取同一个文件。

最后一个需要解决的问题是，一个惰性计算有一个文件句柄在其后关闭。我们使用\acode{rnf}来强制从\acode{withChunks}返回之前完成所有的处理。然后，我们可以显式的关闭
文件句柄，因为它们不应该再被读取。如果必须在程序中使用惰性 I/O，通常最好是像这样做成“防火墙”，这样便不会在代码没有预料到的部分发生问题。

\subsubsection*{高效的寻找行对称的代码块}

由于服务器日志文件是面向行的，因此我们需要一种有效的方法将文件分成大块，同时确保每个块以行边界结束。由于块的大小可能有几十兆字节，因此我们不希望扫描块中的所有数据来
确定其最终边界的位置。

无论选择固定的块大小还是固定数量的块，我们的方法都是有效的。这里我们选择后者。首先寻找块末尾的大致位置，然后向前扫描，直到找到换行符；然后在换行符之后开始下一块，
并重复该过程。

\begin{lstlisting}[language=Haskell]
  lineChunks :: Int -> FilePath -> IO [ChunkSpec]
  lineChunks numChunks path = do
    bracket (openFile path ReadMode) hClose $ \h -> do
      totalSize <- fromIntegral `liftM` hFileSize h
      let chunkSize = totalSize `div` fromIntegral numChunks
          findChunks offset = do
            let newOffset = offset + chunkSize
            hSeek h AbsoluteSeek (fromIntegral newOffset)
            let findNewline off = do
                  eof <- hIsEOF h
                  if eof
                    then return [CS offset (totalSize - offset)]
                    else do
                      bytes <- LB.hGet h 4096
                      case LB.elemIndex '\n' bytes of
                        Just n -> do
                          chunks@(c : _) <- findChunks (off + n + 1)
                          let coff = chunkOffset c
                          return (CS offset (coff - offset) : chunks)
                        Nothing -> findNewline (off + LB.length bytes)
            findNewline newOffset
      findChunks 0
\end{lstlisting}

最后一个块最终会比之前的块短一点，但在实践中这种差异是微不足道的。

\subsubsection*{记录行数}

下面这个简单的例子说明了如何使用刚刚构建好的脚手架：

\begin{lstlisting}[language=Haskell]
  module Main where

  import Control.Monad (forM_)
  import Control.Parallel.Strategies (rdeepseq)
  import qualified Data.ByteString.Lazy.Char8 as LB
  import Data.Int (Int64)
  import LineChunks
  import MapReduce
  import System.Environment (getArgs)

  lineCount :: [LB.ByteString] -> Int64
  lineCount = mapReduce rdeepseq (LB.count '\n') rdeepseq sum

  main :: IO ()
  main = do
    args <- getArgs
    forM_ args $ \path -> do
      numLines <- chunkedReadWith lineCount path
      putStrLn $ path <> ": " <> show numLines
\end{lstlisting}

注：原文的\acode{rnf}已由\acode{rdeepseq}替代。

如果编译项目时带上\acode{ghc -O2 --make -threaded}，在初始运行“预热”文件系统缓存后，它应该可以良好的运行（运行时使用\acode{+RTS -N2}双核）。

\subsubsection*{查找最流行的 URLs}

下面的例子中，我们统计每个 URL 被访问了多少次。

\begin{lstlisting}[language=Haskell]
  module Main where

  import Control.Monad (forM_)
  import Control.Parallel.Strategies (rseq)
  import qualified Data.ByteString.Char8 as S
  import qualified Data.ByteString.Lazy.Char8 as L
  import Data.List (foldl', sortBy)
  import qualified Data.Map as M
  import LineChunks (chunkedReadWith)
  import MapReduce (mapReduce)
  import System.Environment (getArgs)
  import Text.Regex.PCRE.Light (compile, match)

  countURLs :: [L.ByteString] -> M.Map S.ByteString Int
  countURLs = mapReduce rseq (foldl' augment M.empty . L.lines) rseq M.unions
    where
      augment m line =
        case match (compile pttn []) (strict line) [] of
          Just (_ : url : _) -> M.insertWith (+) url 1 m
          _ -> m
      strict = S.concat . L.toChunks
      pttn = S.pack "\"(?:GET|POST|HEAD) ([^ ]+) HTTP/"

  main :: IO ()
  main = do
    args <- getArgs
    forM_ args $ \path -> do
      m <- chunkedReadWith countURLs path
      let mostPopular (_, a) (_, b) = compare b a
      mapM_ print . take 10 . sortBy mostPopular . M.toList $ m
\end{lstlisting}

略。

\subsubsection*{总结}

给定一个非常合适模型的问题，\acode{MapReduce}编程模型允许我们在 Haskell 中编写具有良好性能的“任意”并行程序，并只需要很少的额外工作量。我们可以很容易的将这个想法
扩展到使用其他数据源，例如文件集合或者通过网络获取的数据。

很多情况下，性能瓶颈将以足够高的速率流式传输数据，以跟上核心的处理能力。例如，如果我们尝试在没有缓存在内存中或从高带宽存储阵列流式传输的文件上使用上述任意一程序，我们
将花费大部分时间等待磁盘 I/O，而不会从多核中获得任何好处。

\end{document}
