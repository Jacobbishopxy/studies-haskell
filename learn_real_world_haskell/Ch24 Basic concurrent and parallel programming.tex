\documentclass[./main.tex]{subfiles}

\begin{document}

\subsection*{定义并发与并行}

一个\textit{并发}程序需要在同一时刻执行若干不相关的任务。假设一个游戏服务器：它由多个组件构成，每个组件都要与外界进行复杂的交互。某个组件可能是处理多用户聊天；若干个
则是处理用户的输入，并将更新后的状态返回给用户；另外一些则是执行物理计算。

一个并发程序的正确操作并不需要多核，不过多核可以增强性能与响应。

相反的，一个\textit{并行}程序解决单个问题。假设一个金融模型用于预测单个股票下一分钟的价格。如果我们希望将此模型应用在交易所中的每个股票上，例如预计哪只票可以进行买卖，
那么通过五百个核进行计算肯定比一个核计算更能快速的得到一个答案。这种情况下，并行程序通常不依靠多核也能正确工作。

另一个用于区分两者差别的方法在于它们如何与外界进行交互。根据定义，一个并发程序会持续不断地进行网络协议，数据库等处理。而一个典型的并行程序则更为集中：它流式的接受数据，
处理一段时间（进行少许 I/O），然后流式的输出数据。

很多传统语言会模糊这两者之间的边界，因为它们强制程序员使用相同的方式构建这两种程序。

\subsection*{使用线程的并发编程}

作为并发程序的构建块，大多数编程语言都提供了创建多个独立控制线程的方法。Haskell 也不例外，尽管在 Haskell 中使用线程编程看起来与其他语言有些不同。

Haskell 中，一个线程就是一个独立其它线程执行的\acode{IO}操作。要创建一个线程，我们需要导入\acode{Control.Concurrent}模块并使用\acode{forkIO}函数。

\begin{lstlisting}[language=Haskell]
  ghci> :m +Control.Concurrent
  ghci> :t forkIO
  forkIO :: IO () -> IO ThreadId
  ghci> :m +System.Directory
  ghci> forkIO (writeFile "xyzzy" "seo craic nua!") >> doesFileExist "xyzzy"
  False
\end{lstlisting}

\subsubsection*{线程是不确定的}

GHC 的运行时组件没有指定执行线程的顺序。因此，在上面的示例中，新线程创建的文件\textit{xyzzy}在原始线程检查其存在时可能已经创建，也可能还没有创建。如果我们尝试此
示例一次，然后删除\textit{xyzzy}并再次尝试，那么第二次可能会得到不同的结果。

\subsubsection*{隐藏延迟}

假设有一个很大的文件需要被压缩并写入磁盘，但是又想要迅速的处理用户的输入，使用户感受到程序的快速响应。可以使用\acode{forkIO}在另一个线程中进行文件写入。

\begin{lstlisting}[language=Haskell]
  import Codec.Compression.GZip ( compress )
  import Control.Concurrent (forkIO)
  import Control.Exception (SomeException, handle)
  import qualified Data.ByteString.Lazy as L

  main :: IO ()
  main = do
    putStrLn "Enter a file to compress>"
    name <- getLine
    handle (print :: SomeException -> IO ()) $ do
      content <- L.readFile name
      _ <- forkIO $ compressFile name content
      return ()
    where
      compressFile path = L.writeFile (path ++ ".gz") . compress
\end{lstlisting}

注：原文使用的\acode{readline}库不再适用，另外\acode{print}也需要显式声明类型。

因为这里使用了惰性的\acode{ByteString} I/O，剩下的只需要在主线程中打开文件。实际的读取则是在另一条线程中进行。

\acode{handle print}的使用提供了廉价打印错误信息的方法，例如文件名不存在。

\subsection*{线程间的简单通讯}

在两个线程之间共享信息的最简单方法是让它们都是用一个变量。在我们的文件压缩例子中，主线程与另一个线程共享文件的名称以及内容。因为 Haskell 数据在默认情况下是不可变的，
所以这没有任何的风险：两个线程都不能修改另一个线程所见的文件名或内容。

我们通常需要线程主动地与其他线程进行交互。例如，GHC 并没有为线程提供查看另一个线程是否正在执行、已经完成或是崩溃的方法。不过它提供了一个\textit{同步变量}类型，即
\acode{MVar}，允许我们使用它来达到目的。

\acode{MVar}的作用像是一个单元素的盒子：它要么是满的要么是空的。我们可以将某个东西放入盒子，使其满上，或是拿出使其空置。

\begin{lstlisting}[language=Haskell]
  ghci> import Control.Concurrent
  ghci> :t putMVar
  putMVar :: MVar a -> a -> IO ()
  ghci> :t takeMVar
  takeMVar :: MVar a -> IO a
\end{lstlisting}

如果我们尝试将一个值放入已经满的\acode{MVar}中，线程则会进入睡眠直到其它线程将该值取出。同样的，如果尝试从一个空置的\acode{MVar}中取值，线程也会进入睡眠直到其它的
线程将值放入。

\begin{lstlisting}[language=Haskell]
  import Control.Concurrent

  communicate :: IO ()
  communicate = do
    m <- newEmptyMVar
    _ <- forkIO $ do
      v <- takeMVar m
      putStrLn $ "received" ++ show v
    putStrLn "sending"
    putMVar m "wake up"
\end{lstlisting}

\acode{newEmptyMVar}函数有一个描述性的名称；要创建一个非空的\acode{MVar}则使用\acode{newMVar}。

\begin{lstlisting}[language=Haskell]
  ghci> :t newEmptyMVar
  newEmptyMVar :: IO (MVar a)
  ghci> :t newMVar
  newMVar :: a -> IO (MVar a)
\end{lstlisting}

测试：

\begin{lstlisting}[language=Haskell]
  ghci> :l MVarExample.hs
  [1 of 2] Compiling Main             ( MVarExample.hs, interpreted )
  Ok, one module loaded.
  ghci> communicate
  sending
  received "wake up"
\end{lstlisting}

如果你拥有传统语言中并发编程的经验，那么可以将\acode{MVar}看做是用有两个目的的助力。

\begin{enumerate}
  \item 将一个信息从一个线程发送至另一个线程，例如，消息。
  \item 为线程间共享的可变数据提供\textit{互斥}。当数据没有被任何线程使用时，将其放入\acode{MVar}中，另一个线程将其临时取出进行读取或者修改。
\end{enumerate}

\subsection*{主线程与其它线程的等待}

GHC 的运行时系统将程序的原始控制线程与其它线程区别对待。当该线程完成执行，运行时系统认为程序作为一个整体已经完成。如果又其它线程仍在执行，它们则会被终止。

因此，当我们有不能杀死的长时间运行线程时，我们必须做出特殊安排以确保主线程在其他线程完成之前不会完成。下面是一个小库使其易于实现：

\begin{lstlisting}[language=Haskell]
  import Control.Concurrent
  import Control.Exception
  import Control.Monad
  import Data.Map as M

  data ThreadStatus
    = Running
    | Finished -- terminated normally
    | Threw IOException -- changed from `Exception`
    deriving (Eq, Show)

    -- | Create a new thread manager.
    newManager :: IO ThreadManager

    -- | Create a new managed thread.
    forkManaged :: ThreadManager -> IO () -> IO ThreadId

    -- | Immediately return the status of a managed thread.
    getStatus :: ThreadManager -> ThreadId -> IO (Maybe ThreadStatus)

    -- | Block until a specific managed thread terminates.
    waitFor :: ThreadManager -> ThreadId -> IO (Maybe ThreadStatus)

    -- | Block until all managed threads terminate.
    waitAll :: ThreadManager -> IO ()
\end{lstlisting}

我们使用通常的方法来保持\acode{ThreadManager}类型的抽象：我们将其包装在\acode{newtype}中，并防止用于创建该类型的值。在模块导出中，给出类型构造函数以及
构造管理者的 IO 操作，并不导出数据构造函数。

\begin{lstlisting}[language=Haskell]
  module NiceFork
    ( ThreadManager,
      newManager,
      forkManaged,
      getStatus,
      waitFor,
      waitAll,
    )
  where
\end{lstlisting}

对于\acode{ThreadManager}的实现，我们维护一个从线程 ID 到线程状态的映射：

\begin{lstlisting}[language=Haskell]
  -- Thread map
  newtype ThreadManager
    = Mgr (MVar (M.Map ThreadId (MVar ThreadStatus)))
    deriving (Eq)

  -- Create a new thread manager
  newManager :: IO ThreadManager
  newManager = Mgr <$> newMVar M.empty
\end{lstlisting}

这里有两个级别的\acode{MVar}使用。首先是\acode{Map}，通过替换一个新版本允许我们对其进行“修改”。同时还可以确保使用\acode{Map}的任何线程看到的是一致的视图。

对于管理的每个线程，我们维护一个\acode{MVar}。每个线程的\acode{MVar}开始时为空，即表明线程正在执行。当线程结束或被未捕获的异常杀死时，将该信息放入\acode{MVar}中。

要创建一个线程并观察其状态，我们必须执行一点记录性的操作。

\begin{lstlisting}[language=Haskell]
  -- Create a new managed thread and watch its status
  forkManaged :: ThreadManager -> IO () -> IO ThreadId
  forkManaged (Mgr mgr) body =
    -- safely modify an MVar
    modifyMVar mgr $ \m -> do
      state <- newEmptyMVar
      tid <- forkIO $ do
        result <- try body
        putMVar state $ either Threw (const Finished) result
      return (M.insert tid state m, tid)
\end{lstlisting}

\subsubsection*{安全的修改 MVar}

在上述\acode{forkManaged}中使用的\acode{modifyMVar}函数非常有用：它是一个安全的\acode{takeMVar}与\acode{putMVar}组合。

\begin{lstlisting}[language=Haskell]
  ghci> :t modifyMVar
  ved "wake up!"
  modifyMVar :: MVar a -> (a -> IO (a, b)) -> IO b
\end{lstlisting}

它从\acode{MVar}中取值，将其传递给一个函数。该函数可以同时生成一个新值并返回一个结果。如果该函数抛出异常，那么\acode{modifyMVar}则会将原有值放回\acode{MVar}中，
否则将新值放入其中。它返回函数的另一个元素作为自己的结果。

当我们使用\acode{modifyMVar}而不是通过\acode{takeMVar}与\acode{putMVar}来手动管理一个\acode{MVar}时，我们避免了两种常见的并行错误：

\begin{enumerate}
  \item 忘记将值放回\acode{MVar}。这可能导致\textit{死锁}，在这种情况下，一些线程永远在等待一个永远不会向其放入值的\acode{MVar}。
  \item 未能考虑到抛出异常的可能，从而中断了代码流程。这可能导致\textit{应该}发生的对\acode{putVar}的调用实际上并没有发生，从而再次导致死锁。
\end{enumerate}

因为这些优秀的安全属性，尽可能的使用\acode{mofigyMVar}是一个明智的选择。

我们可以采用\acode{modifyMVar}遵循的模式，将其应用于许多其它资源管理的情况中。以下是该模式的步骤：

\begin{enumerate}
  \item 获取资源
  \item 将资源传递给函数进行处理
  \item 总是释放资源，即使该函数抛出了异常。如果出现这种情况，将异常重新抛出使其能被应用代码捕获。
\end{enumerate}

除了安全之外，这种方法还有另一个好处：它可以使我们的代码更简短且更容易理解。从上面的\acode{forkManaged}中可以看出，Haskell 对于匿名函数的轻量级语法使得这种风格的
编码在视觉上不那么突兀。

以下是\acode{modifyMVar}的定义，我们可以看到这种模式的特定样式：

\begin{lstlisting}[language=Haskell]
  import Control.Concurrent (MVar, putMVar, takeMVar)
  import Control.Exception (evaluate, mask, onException)

  modifyMVar' :: MVar a -> (a -> IO (a, b)) -> IO b
  modifyMVar' m io =
    mask $ \restore -> do
      a <- takeMVar m
      (a', b) <- restore (io a >>= evaluate) `onException` putMVar m a
      putMVar m a'
      return b
\end{lstlisting}

注：详见\href{https://hackage.haskell.org/package/ghc-internal-9.1001.0/docs/src/GHC.Internal.Control.Concurrent.MVar.html#modifyMVar}{此处}。

无论是在处理网络连接、数据库句柄还是 C 库管理的数据，它都能轻松的适应用户的特定需求。

\subsubsection*{查找线程的状态}

\acode{getStatus}函数能告诉我们一个线程的当前状态。如果该线程不再被管理（或者是从来没有被管理过），它返回\acode{Nothing}。

\begin{lstlisting}[language=Haskell]
  -- Immediately return the status of a managed thread
  getStatus :: ThreadManager -> ThreadId -> IO (Maybe ThreadStatus)
  getStatus (Mgr mgr) tid =
    modifyMVar mgr $ \m ->
      case M.lookup tid m of
        Nothing -> return (m, Nothing)
        Just st -> tryTakeMVar st >>= mst m
    where
      mst m' mm = case mm of
        Nothing -> return (m', Just Running)
        Just sth -> return (M.delete tid m', Just sth)
\end{lstlisting}

如果线程仍在运行，其返回\acode{Just Running}。否则，它表示该线程为何被终结，同时停止管理该线程。

如果\acode{tryTakeMVar}函数找到\acode{MVar}是空的，它便立刻返回\acode{Nothing}而不是阻塞。

\begin{lstlisting}[language=Haskell]
  ghci> :t tryTakeMVar
  tryTakeMVar :: MVar a -> IO (Maybe a)
\end{lstlisting}

否则，它像通常那样从\acode{MVar}中提取值。

\acode{waitFor}函数的行为类似，不过并不是立刻返回，它会阻塞，直到给定的线程在返回之前终止。

\begin{lstlisting}[language=Haskell]
  -- Block until a specific managed thread terminates
  waitFor :: ThreadManager -> ThreadId -> IO (Maybe ThreadStatus)
  waitFor (Mgr mgr) tid = do
    maybeDone <- modifyMVar mgr $ \m ->
      return $ case M.updateLookupWithKey (\_ _ -> Nothing) tid m of
        (Nothing, _) -> (m, Nothing)
        (done, m') -> (m', done)
    case maybeDone of
      Nothing -> return Nothing
      Just st -> Just <$> takeMVar st
\end{lstlisting}

它首先提取保存线程状态的\acode{MVar}（如果存在）。\acode{Map}类型的\acode{updateLookupWithKey}函数很有用：它将查找与修改或删除值结合起来。

\begin{lstlisting}[language=Haskell]
  ghci> :m +Data.Map
  ghci> :t updateLookupWithKey
  updateLookupWithKey :: (Ord k) =>
                         (k -> a -> Maybe a) -> k -> Map k a -> (Maybe a, Map k a)
\end{lstlisting}

这种情况下，我们希望总是删除持有线程状态的\acode{MVar}（如果它存在），这样我们的线程管理器将不再管理线程。如果有要提取的值，我们从\acode{MVar}中获取线程的退出状态
并返回它。

最后一个有用的函数就是简单的等待所有管理的线程完成，并忽略它们的退出状态：

\begin{lstlisting}[language=Haskell]
  -- Block until all managed threads terminate
  waitAll :: ThreadManager -> IO ()
  waitAll (Mgr mgr) = modifyMVar mgr es >>= mapM_ takeMVar
    where
      es m = return (M.empty, M.elems m)
\end{lstlisting}

\subsubsection*{编写更紧凑的代码}

上面\acode{waitFor}的定义不太令人满意，因为两个地方执行了类似的代码：在由\acode{modifyMVar}调用的函数内部，以及在它的返回值上。

当然，我们可以应用前面遇到的一个函数来消除这种重复。由\acode{Control.Monad}模块带来的\acode{join}可以解决这个问题。

\begin{lstlisting}[language=Haskell]
  ghci> :m +Control.Monad
  ghci> :t join
  join :: (Monad m) => m (m a) -> m a
\end{lstlisting}

这里的技巧就是通过让第一个表达式返回应该从\acode{modifyMVar}返回后执行的 IO 操作来摆脱第二个\acode{case}表达式。这里使用了\acode{join}：

\begin{lstlisting}[language=Haskell]
  waitFor (Mgr mgr) tid =
    join . modifyMVar mgr $ \m -> return $
      case M.updateLookupWithKey (\_ _ -> Nothing) tid m of
        (Nothing, _) -> (m, return Nothing)
        (Just st, m') -> (m', Just <$> takeMVar st)
\end{lstlisting}

这是一个有趣的想法：我们可以在纯函数代码中创建 monadic 函数或操作，然后传递它，直到最终可用的单元中结束。一旦我们的开发令其有意义，这可能是一种灵活的编写代码的方式。

\subsection*{通过隧道进行交流}

对于线程之间的一次性通信，\acode{MVar}是非常好的选择。另一种类型\acode{Chan}提供单向通信通道。下面是一个简单的例子：

\begin{lstlisting}[language=Haskell]
  import Control.Concurrent (forkIO, newChan, readChan, writeChan)

  chanExample :: IO ()
  chanExample = do
    ch <- newChan
    _ <- forkIO $ do
      writeChan ch "hello world"
      writeChan ch "now i quit"
    readChan ch >>= print
    readChan ch >>= print
\end{lstlisting}

如果\acode{Chan}是空的，\acode{readChan}会阻塞知道有值可以读取。\acode{writeChan}函数永远不会阻塞：它会立刻向\acode{Chan}中写入一个新值。

\subsection*{几点重要的须知}

\subsubsection*{MVar 与 Chan 是 non-strict 的}

正如大多数 Haskell 容器类型一样，\acode{MVar}与\acode{Chan}都是 non-strict 的：它们都不计算其内容。提到这点并不是因为它是一个问题，而是因为它是一个常见的盲点：
人们倾向认为这些类型是 strict 的，也许是因为它们在\acode{IO}单子中使用。

对于其它容器类型，错误猜测\acode{MVar}或\acode{Chan}类型的 strict 性的结果通常是空间或性能泄漏。这里有一个合理的设想。

fork 一个线程，在另一个核执行昂贵计算。

\begin{lstlisting}[language=Haskell]
  import Control.Concurrent

  notQuiteRight :: IO ()
  notQuiteRight = do
    mv <- newEmptyMVar
    _ <- forkIO $ expensiveComputation_stricter mv
    -- some other activity
    result <- takeMVar mv
    print result

  expensiveComputation_stricter :: MVar [Char] -> IO ()
  expensiveComputation_stricter mv = do
    let a = "this is"
        b = "not really"
        c = "all that expensive"
    putMVar mv (a ++ b ++ c)
\end{lstlisting}

这像是做某事儿，同时将其结果返回给\acode{MVar}：

\begin{lstlisting}[language=Haskell]
  expensiveComputation_stricter :: MVar [Char] -> IO ()
  expensiveComputation_stricter mv = do
    let a = "this is"
        b = "not really"
        c = "all that expensive"
    putMVar mv (a ++ b ++ c)
\end{lstlisting}

当我们从父线程的\acode{MVar}中获取结果并试图对它做一些事情时，我们的线程开始疯狂的计算，因为我们从未强迫计算发生在另一个线程内！

像往常一样，解决方案很简单，一旦我们知道存在潜在的问题：为 fork 的线程增加 strict 性，以确保计算在原线程发生。strict 最好放在一个地方，以免遗忘。

\begin{lstlisting}[language=Haskell]
  {-# LANGUAGE BangPatterns #-}

  import Control.Concurrent (MVar, putMVar, takeMVar)
  import Control.Exception (IOException, catch, mask, onException, throw)

  modifyMVar_strict :: MVar a -> (a -> IO a) -> IO ()
  modifyMVar_strict m io = mask $ \restore -> do
    a <- takeMVar m
    !a' <- restore (io a) `onException` putMVar m a
    putMVar m a'

  modifyMVar_strict' :: MVar a -> (a -> IO a) -> IO ()
  modifyMVar_strict' m io = mask $ \restore -> do
    a <- takeMVar m
    !a' <-
      restore (io a) `catch` \e ->
        putMVar m a >> throw (e :: IOException)
    putMVar m a'
\end{lstlisting}

注：原文中\acodegrn{Control.Exception}库提供的\acode{block}与\acode{unblock}已被废弃，现在改用\acode{mask}来实现。

上述代码中的\acode{!}模式简单易用，但这并不总保证数据总能被计算。

\subsubsection*{Chan 是无边界的}

由于\acode{writeChan}总能立即成功，所以使用\acode{Chan}有着潜在的风险。如果一个线程的写比另一个线程的读要多，那么这个线程将以一种不受约束的方式增长：未读的消息
将随着读取越来越落后而堆积起来。

\subsection*{共享状态仍然很困难}

尽管与其它语言相比，Haskell 在线程间共享数据有不同的原语，但它仍然面临相同的基本问题：编写正确的并发程序非常困难。实际上，其它语言中并发编程的一些缺陷同样适用
于 Haskell。两个比较著名的问题就是\textit{死锁}与\textit{饥饿}。

\subsubsection*{死锁}

在\textit{死锁}的情况下，两个或多个线程在访问共享资源时永远的卡住。一个典型的多线程死锁问题就是忘记申请锁的顺序。这类型的 bug 太常见了，即：\textit{锁序反转}。
虽然 Haskell 不提供锁，但是\acodegrn{MVar}类型仍然容易出现顺序反转的问题。下面是一个简单的例子：

\begin{lstlisting}[language=Haskell]
  import Control.Concurrent (MVar, forkIO, modifyMVar_, newMVar, yield)

  nestedModification :: (Num a1, Num a2) => MVar a2 -> MVar a1 -> IO ()
  nestedModification outer inner = do
    modifyMVar_ outer $ \x -> do
      yield -- force this thread to temporarily yield the CPU
      modifyMVar_ inner $ \y -> return $ y + 1
      return $ x + 1
    putStrLn "done"

  main :: IO ()
  main = do
    a <- newMVar (1 :: Int)
    b <- newMVar (2 :: Int)
    _ <- forkIO $ nestedModification a b
    _ <- forkIO $ nestedModification b a

    return ()
\end{lstlisting}

如果将此运行在\textbf{ghci}中，通常（并不总是）打印不了任何东西，这表明两个线程都被卡住了。

\acode{nestedModification}函数的问题很容易发现。在第一个线程中，我们取\acode{MVar a}，接着取\acode{b}；在第二个线程中，我们取\acode{b}然后取\acode{a}。
如果第一个线程成功取到了\acode{a}，第二个线程取\acode{b}，两个线程都将阻塞：每个线程都试图取另一个线程已经清空了的\acode{MVar}，所以两个线程都不会有进展。

各种语言中，解决顺序反转的常用方法是在获取资源时始终遵循一致的顺序。由于这种方法需要手动遵循编码约定，因此在实践中很容易被忽略。

更复杂的是，这些反转问题在实际代码很难被发现。\acode{MVar}的获取通常分布在不同文件中的若干函数中，这使得肉眼检测变得更加棘手。更糟糕的是，这些问题往往是
\textit{间歇性的}，这让它们变得很难复现，更不用说隔离和修复了。

\subsubsection*{饥饿}

并发软件也很容易出现\textit{饥饿}，即一个线程“霸占”共享资源，阻止另一个线程使用它。很容易想象这是如何发生的：一个线程用执行 100 毫秒的主体调用\acode{modifyMVar}，
而另一个线程用执行 1 毫秒的主体在同一个\acode{MVar}上调用\acode{modifyMVar}。在第一个线程将一个值放回\acode{MVar}之前，第二个线程无法取得任何进展。

\acode{MVar}类型的 non-strict 性质可能加剧或导致饥饿问题。如果我们在\acode{MVar}中放入一个计算成本很高的东西，然后把它从\acode{MVar}中取出，放到一个看起来很
轻量的线程中，那么这个线程就会突然变得高计算成本，因为它必须计算这个东西。

\subsubsection*{还有任何的希望吗？}

幸运的是，在这里介绍的用于并发性的 api 并不是结局。Haskell 有一个名为软件事务性内存的功能，使用起来更容易也更安全。我们将会在第二十八中进行讨论。

\subsection*{使用多核 GHC}

默认情况下，GHC 生成的程序只使用一个内核，即使我们显式的编写并发代码也是如此。要使用多核，我们必须明确的选择这样做。在生成可执行程序时，我们在链接时做出此选择。

\begin{itemize}
  \item “非线程”运行库在单个操作系统线程中运行所有的 Haskell 线程。这个运行时对于\acode{MVar}中创建线程和传递数据非常高效。
  \item “线程”运行库使用多个操作系统线程来运行 Haskell 线程。它在创建线程和使用\acode{MVar}方面有更多的开销。
\end{itemize}

如果我们将\acode{-thread}选项传递给编译器，它将把我们的程序链接到线程运行时库。在编译库或源文件时不需要使用\acode{-thread}，只有在最终生成可执行文件时才需要使用
\acode{-thread}。

即使我们为程序选择了线程运行时，当我们运行它时，它仍然默认只使用一个内核。我们必须明确的告诉运行时要使用多少内核。

\subsubsection*{运行时选项}

我们可以在程序的命令行上将选项传递给 GHC 的运行时系统。在将控制权交给代码之前，运行时扫描程序的参数，以查找特殊的命令行选项\acode{+RTS}。它将之后的所有内容，直到特殊
选项\acode{-RTS}，解释为运行时系统的选项，而不是我们的程序。它在代码中隐藏了所有这些选项。当我们使用\acode{System.Environment}模块的\acode{getArgs}函数来
获取我们的命令行参数，我们不会在列表中找到任何运行时选项。

线程运行时接受一个选项\acode{-N}。它有一个参数，指定\acode{GHC}运行时系统应该使用的内核数量。选项解析器是挑剔的：\acode{-N}和后面的数字之间不能有空格。选项
\acode{-N4}是可以接受的，而\acode{-N 4}则不行。

\subsubsection*{为 Haskell 寻找有效核术}

\acode{GHC.Conc}模块导出了一个变量，\acode{numCapabilities}，可以告诉我们运行时系统通过\acode{-N} RTS 选项分配了多少核数。

\begin{lstlisting}[language=Haskell]
  import GHC.Conc (numCapabilities)
  import System.Environment (getArgs)

  main :: IO ()
  main = do
    args <- getArgs
    putStrLn $ "command line arguments: " <> show args
    putStrLn $ "number of cores: " <> show numCapabilities
\end{lstlisting}

如果编译并运行上述程序，就可以看到运行时的选项在程序中并不可见，但是可以看到多少核可以用于运行。

\begin{lstlisting}[language=Haskell]
  $ ghc -c NumCapabilities.hs
  $ ghc -threaded -o NumCapabilities NumCapabilities.o
  $ ./NumCapabilities +RTS -N4 -RTS foo
  command line arguments: ["foo"]
  number of cores: 4
\end{lstlisting}

\subsubsection*{使用合适的运行时}

使用哪个运行时的决定并不完全明确。虽然线程运行时可以使用多个内核，但它有一个代价：线程和在它们之间共享数据比使用非线程运行时更昂贵。

在许多现实世界的并发程序中，单个线程将花费大部分时间等待网络请求或响应。这些情况下，如果一个 Haskell 程序为成千上万个并发客户提供服务，那么非线程运行时的较低开销可能
会有所帮助。例如，与其让单个服务器程序在四个核上使用线程运行时，不如将服务器设计成可以同时运行它的四个副本，并使用非线程运行时。如此可能会得到更好的性能。

\subsection*{Haskell 中的并行编程}

现在我们将重点转向并行编程。对于许多计算成本很高的问题，如果我们可以将解决方案分离，并同时在多个核上进行计算，那么就可以更快的计算出结果。

\subsubsection*{Normal form 以及 head normal form}

熟知的\acode{seq}函数将表达式求值为我们所说的头范式（缩写 HNF）。它一旦到达最外层的构造函数（“头部”）就会停止。这与正常范式（NF）不同，在正常范式（NF）中，表达式
是完全求值的。

我们还会听到 Haskell 程序员提到的弱头范式（WHNF）。对于正常数据，若头正常范式与头正常范式相同。这种差别只出现在函数上，不过这过于深奥了，在这里不进行讨论。

\subsubsection*{序列化排序}

以下是一个使用分治方法的普通 Haskell 函数，其用于列表排序。

\begin{lstlisting}[language=Haskell]
  -- divide-and-conquer
  sort :: (Ord a) => [a] -> [a]
  sort (x : xs) = lesser ++ x : greater
    where
      lesser = sort [y | y <- xs, y < x]
      greater = sort [y | y <- xs, y >= x]
  sort _ = []
\end{lstlisting}

这个函数的灵感来源于著名的快排算法，它是 Haskell 程序员中的经典：它经常在 Haskell 教程的早期以一行代码的形式出现，用 Haskell 的表达性来戏弄读者。这里，我们将代码
分成几行，以便于比较串行与并行的版本。

下面是\acode{sort}操作的简单介绍：

\begin{enumerate}
  \item 它从列表中选择一个元素。这被称为\textit{轴心点 pivot}。任何元素都可以是轴心点；第一种模式是最容易匹配的。
  \item 它为小于轴心点的所有元素创建一个子列表，并对它们进行递归排序。
  \item 它为大于或等于轴心点的所有元素创建一个子列表，并对它们进行递归排序。
  \item 合并两个排序好的子列表。
\end{enumerate}

\subsubsection*{转换代码为并行代码}

并行版本的函数比初版稍微复杂了一些：

\begin{lstlisting}[language=Haskell]
  import Control.Parallel (par, pseq)

  parSort :: (Ord a) => [a] -> [a]
  parSort (x : xs) = force greater `par` (force lesser `pseq` (lesser ++ x : greater))
    where
      lesser = parSort [y | y <- xs, y < x]
      greater = parSort [y | y <- xs, y >= x]
  parSort _ = []
\end{lstlisting}

我们几乎没有扰乱代码：我们所添加的只是三个函数，\acode{par}，\acode{pseq}以及\acode{force}。

\acode{par}函数由\acode{Control.Parallel}模块提供。它的左右与\acode{seq}类似：将左参求值为弱头范式，并返回右参。顾名思义，\acode{par}可以与正在发生的任何
其它求值并行的求其左参。

至于\acode{pseq}，它与\acode{seq}类似：先将左边的表达式求值为 WHNF，然后返回右边的表达式。两者之前的区别很微妙，但对于并行程序而言很重要：如果编译器看到先求右参会
提高性能，则不会\textit{承诺}求\acode{seq}的左参。这种灵活性对于在一个核上执行的程序而言很好，但是对于在多个核上运行的代码而言就不够强劲了。相反编译器\textit{保证}
\acode{pseq}会先求左参，再求右参。

这些对于我们代码的修改而言是值得关注的，因为我们不需要说明所有的事情。

\begin{itemize}
  \item 使用多少核
  \item 什么线程用于彼此间的通讯
  \item 如何在可用核中拆分任务
  \item 什么数据是线程间共享的，什么是私有的
  \item 所有部分完成后如何收尾
\end{itemize}

\subsubsection*{知道并行计算什么}

从并行 Haskell 代码中获得良好性能的关键是找到有意义的工作块来并行执行。Non-strict 的计算会妨碍到这点，这就是在并行排序中使用\acode{force}函数的原因。为了更好的
解释\acode{force}函数的作用，我们先来看一个错误的例子：

\begin{lstlisting}[language=Haskell]
  sillySort :: (Ord a) => [a] -> [a]
  sillySort (x : xs) = greater `par` (lesser `pseq` (lesser ++ x : greater))
    where
      lesser = sillySort [y | y <- xs, y < x]
      greater = sillySort [y | y <- xs, y >= x]
  sillySort _ = []
\end{lstlisting}

看一下每个使用\acode{par}处的小改变。没有用\acode{force lesser}与\acode{force greater}，而是直接计算\acode{lesser}与\acode{greater}。

请记住，对 WHNF 的求值只计算足以查看其最外层构造函数的表达式。这个错误示例中，我们将每个排序的子列表求值为 WHNF。由于每种情况下最外层的构造函数都只是一个列表构造函数，
因此我们实际上只强制对每个排序子列表的第一个元素求值！每个列表的其它所有元素保持未求值。换言之，几乎没有并行的做任何有用的工作：\acode{sillySort}几乎是完全顺序的。

我们通过\acode{force}函数强制整个列表，在返回给构造函数之前进行计算，避免上述情况发生：

\begin{lstlisting}[language=Haskell]
  force :: [a] -> ()
  force xs = go xs `pseq` ()
    where
      go :: [a] -> Integer
      go (_ : xs') = go xs'
      go [] = 1
\end{lstlisting}

注意我们并不在乎列表中的是什么；我们遍历列表至最后，使用\acode{pseq}。这里显然没有魔法：只是使用我们对 Haskell 计算模型的理解。又因为我们将在\acode{par}或
\acode{pseq}的左侧使用\acode{force}，我们不需要返回一个有意义的值。

当然很多情况下，我们也需要强制对列表中的单个元素求值。下面，我们将讨论这个问题的基于类型的解决方案。

\subsubsection*{par 做了什么承诺}

\acode{par}函数实际上并没有保证一个表达式与另一个表达式并行求值。相反，它承诺如果这样做“有意义”才会这么做。这种模棱两可的不承诺实际上比总是并行求值表达式的保证更有用。
它使运行时系统在遇到\acode{par}的使用时可以自由的采取智能行动。

例如，运行时可能会认为表达式太廉价而不值得并行计算，或者它可能会注意到所有内核当前都很忙，因此“触发”一个新的并行计算将导致可运行线程的数量超过可执行的内核数量。

这种松散的规范反过来又影响了我们编写并行代码的方式。由于\acode{par}在运行时可能有点智能，我们几乎可以在任何喜欢的地方使用它，假设性能不会因为线程争用繁忙的内核而陷入
困境。

\subsubsection*{允许代码并测量性能}

为了测试代码，让我们将\acode{sort}，\acode{parSort}与\acode{parSort2}保存到一个名为\acode{Sorting.hs}的模块中。我们创建了一个小的驱动程序，我们可以使用它
来计时其中一个排序函数的性能。

\begin{lstlisting}[language=Haskell]

  module Main where

  import Data.Time.Clock
  import qualified Sorting as S
  import System.Environment (getArgs)
  import System.Random

  testFunction :: Int -> [Int] -> [Int]
  testFunction n
    | n == 1 = S.sort
    | n == 2 = S.parSort
    | n == 3 = S.seqSort
    | n == 4 = S.parSort2 100000 -- temporary used input
    | otherwise = error "choose n from 1 to 4"

  randomInts :: Int -> StdGen -> [Int]
  randomInts k g =
    let result = take k (randoms g)
     in S.force result `seq` result

  -- test:
  -- cabal run sort-main 3 500000
  main :: IO ()
  main = do
    args <- getArgs

    case args of
      (sortMethod : count : _) -> do
        input <- randomInts (read count) `fmap` getStdGen
        putStrLn $ "We have " ++ show (length input) ++ " elements to sort."
        start <- getCurrentTime
        let sorted = testFunction (read sortMethod) input
        putStrLn $ "Sorted all " ++ show (length sorted) ++ " elements."
        end <- getCurrentTime
        putStrLn $ show (end `diffUTCTime` start) ++ " elapsed."
      _ -> error "SortMain <sortMethod:Int> <count:Int>"
\end{lstlisting}

简单起见，我们通过\acode{testFunction}变量选择在编译时进行基准测试的排序函数。

我们的程序接受一个可选的命令行参数，即要生成的随机列表的长度。

Non-strict 的计算会把性能测量和分析变成雷区。这里有一些潜在的问题，需要我们避免在我们的驱动程序中出现。

\begin{itemize}
  \item \textit{当我们认为在看待一件事物时，实际上却要衡量几件事。}Haskell 的默认伪随机数生成器（PRNG）很慢，\acode{random}函数根据需要生成随机数。

        在记录开始时间之前，我们强制计算列表中的每个元素，并打印列表的长度：这确保我们提前创建了所有需要的随机数。

        如果我们省略这一步，那么将把随机数的生成与并行处理随机数交织在一起。因此，既要测量排序数字的成本，也要测量生成数字的成本（不太明显）。

  \item \textit{不可见的数据依赖。}当我们生成随机数列表时，简单的打印列表的长度将无法执行足够的求值。这将计算列表的主体，而不是其元素。实际的随机数在排序比较它们之前
        不会被计算。

        这可能会对性能产生严重的影响。随机数的值取决于列表中前面随机数的值，但是我们在处理器内核中随机分散了列表元素。如果我们在排序之前没有对列表元素进行计算，那么
        我们将遭受可怕的“乒乓”效应：计算不仅会从一个核跳到另一个核，性能也会受到影响。

        试着从上面的\acode{main}主体中去掉\acode{force}的应用：我们会发现并行代码很容易比非并行代码\textit{慢}三倍。

  \item \textit{当我们相信代码正在执行有意义的工作时，基准测试是一种思考。}为了强制进行排序，在记录结束时间之前打印结果列表的长度。如果没有\acode{putStrLn}要求
        列表的长度来打印它，那么排序就根本不会发生。
\end{itemize}

当我们构建程序时，我们启用了优化和 GHC 的线程运行时。

\begin{lstlisting}[language=Haskell]
  ghc -threaded -O2 -package parallel -package time --make SortMain
  Loaded package environment from /Users/jacobxie/.ghc/aarch64-darwin-9.8.2/environments/default
  [1 of 3] Compiling Sorting          ( Sorting.hs, Sorting.o )
  [2 of 3] Compiling Main             ( SortMain.hs, SortMain.o )
  [3 of 3] Linking SortMain
\end{lstlisting}

注：也可以通过 cabal 或 stack 配置，以下是 cabal 设置：

\begin{lstlisting}
  executable sort-main
  import:           warnings
  default-language: Haskell2010
  main-is:          SortMain.hs
  ghc-options:      -threaded -O2
  build-depends:
    , base
    , my-concurrent
    , parallel
    , random
    , time
\end{lstlisting}

当我们运行程序时，必须告诉 GHC 的运行时需要使用多少内核。开始我们尝试原始排序

\begin{lstlisting}[language=Bash]
  # 使用 GHC 编译后的可执行文件
  ./SortMain +RTS -N1 -RTS 1 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  10.959195s elapsed.

  # 或者使用 cabal
  cabal run sort-main +RTS -N1 -RTS 1 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  10.884864s elapsed.
\end{lstlisting}

注：与原文不同，\acode{SortMain.hs}改造后的第一个 arg 为 1 时，为单线程运行；为 2 时，为并行运行。

启用第二个核并不会太影响效率。

\begin{lstlisting}[language=Haskell]
  ./SortMain +RTS -N2 -RTS 1 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  11.082317s elapsed.
\end{lstlisting}

接下来试试\acode{parSort}，结果并不理想。

\begin{lstlisting}[language=Haskell]
  cabal run sort-main +RTS -N1 -RTS 2 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  13.192825s elapsed.

  cabal run sort-main +RTS -N2 -RTS 2 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  12.038354s elapsed.
\end{lstlisting}

我们在效率上毫无提高，这可能是由于以下两个因素之一：要么\acode{par}本身就很昂贵，要么是我们使用的太多了。为了区分这两种可能性，这里有一个与\acode{parSort}相同的
排序，使用\acode{pseq}而不是\acode{par}。

\begin{lstlisting}[language=Haskell]
  seqSort :: (Ord a) => [a] -> [a]
  seqSort (x:xs) = lesser `pseq` (greater `pseq` (lesser ++ x:greater))
    where
      lesser = seqSort [y | y <- xs, y < x]
      greater = seqSort [y|y <- xs, y >= x]
  seqSort _ = []
\end{lstlisting}

我们也放弃了使用\acode{force}，所以与最初的\acode{sort}相比，我们应该只测量使用\acode{pseq}的成本。单独的\acode{pseq}对性能有什么影响？

\begin{lstlisting}[language=Haskell]
  cabal run sort-main +RTS -N1 -RTS 3 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  12.348779s elapsed.
\end{lstlisting}

这说明\acode{par}与\acode{pseq}的成本相似。该怎么样提高性能呢？

\subsubsection*{性能调优}

在\acode{parSort}中，执行的\acode{par}应用程序数量是要排序的元素数量的两倍。虽然\acode{par}很\textit{廉价}，但是它并不是免费的。当递归的应用\acode{parSort}
时，最终会对单个列表元素应用\acode{par}。在这种细颗粒度下，使用\acode{par}的成本超过了任何可能的有用性。为了减少这种影响，我们在超过某个阈值后切换到非并行排序。

\begin{lstlisting}[language=Haskell]
  parSort2 :: (Ord a) => Int -> [a] -> [a]
  parSort2 d lst@(x : xs)
    | d <= 0 = sort lst
    | otherwise = force greater `par` (force lesser `pseq` (lesser ++ x : greater))
    where
      lesser = parSort2 d' [y | y <- xs, y < x]
      greater = parSort2 d' [y | y <- xs, y >= x]
      d' = d - 1
  parSort2 _ _ = []
\end{lstlisting}

这里，我们停止递归并在可控深度触发新的并行计算。如果我们知道正在处理的数据大小，那么就可以停止细分并在剩余工作量足够小时切换到非并行代码。

\begin{lstlisting}[language=Bash]
  ghc -threaded -O2 -package parallel -package time --make SortMain

  ./SortMain +RTS -N2 -RTS 4 7000000
  We have 7000000 elements to sort.
  Sorted all 7000000 elements.
  7.802378s elapsed.
\end{lstlisting}

注：\acode{testFunction}的函数体中\acode{S.parSort2 100000}参数并不是最优。

略。

\subsection*{并行策略以及 MapReduce}

%

\begin{lstlisting}[language=Haskell]

\end{lstlisting}

\subsubsection*{从计算中分离算法}

%

\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}

\subsubsection*{从策略中分离算法}

%

\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}

\subsubsection*{编写一个简单的 MapReduce 定义}

%

\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}

\subsubsection*{MapReduce 与策略}

%

\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}

\subsubsection*{合理规划}

%

\begin{lstlisting}[language=Haskell]

\end{lstlisting}



\begin{lstlisting}[language=Haskell]

\end{lstlisting}

\subsubsection*{高效的寻找行对称的代码块}


\begin{lstlisting}[language=Haskell]

\end{lstlisting}

\subsubsection*{记录行数}

%

\begin{lstlisting}[language=Haskell]

\end{lstlisting}

\subsubsection*{查找最流行的 URLs}

%

\begin{lstlisting}[language=Haskell]

\end{lstlisting}

\subsubsection*{总结}

%

\end{document}
